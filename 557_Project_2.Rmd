---
title: "557_Project_2BS"
author: "Ben Straub, Hillary Koch, Jiawei Huang, Arif Masrur"
date: "3/15/2017"
output: pdf_document
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
### Testing out Github
rm(list=ls())
par(mfrow=c(1,1))
# Loading packages into R
library(data.table);library(car);library(lars);library(knitr);library(ISLR);library(leaps);library(glmnet);library(MASS);library(reshape)

setwd("/Users/benStraub/Desktop/557/Project 2")
seismic <- read.csv("seismic.csv")
```

# Boring Stuff on the dataset

## Names of Variables

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
# EDA
names(seismic)
```

## Summary Statistics

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
summary(seismic)
```

## Dimensions of Data Matrix

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
dim(seismic)
```

## Check for Normality of Data

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
par(mfrow=c(2,2))

# Barplots of Factor Variables
counts <- table(seismic$seismic)
barplot(counts, main="Seismic Distribution", 
  	xlab="Number of Obs")
counts <- table(seismic$seismoacoustic)
barplot(counts, main="Seismoacoustic Distribution", 
  	xlab="Number of Obs")
counts <- table(seismic$ghazard)
barplot(counts, main="Ghazard Distribution", 
  	xlab="Number of Obs")

## Have a look at the densities

plot(density(seismic$genergy));plot(density(seismic$gpuls))
plot(density(seismic$gdenergy));plot(density(seismic$gdpuls))
plot(density(seismic$maxenergy));plot(density(seismic$nbumps))
plot(density(seismic$nbumps2));plot(density(seismic$nbumps3))
plot(density(seismic$nbumps4));plot(density(seismic$nbumps5))
plot(density(seismic$nbumps6));plot(density(seismic$nbumps7))
plot(density(seismic$nbumps89));plot(density(seismic$energy))

## Plot using a qqplot
qqnorm(seismic$genergy);qqline(seismic$genergy, col = 2)
qqnorm(seismic$gdpuls);qqline(seismic$gdpuls, col = 2)
qqnorm(seismic$gdenergy);qqline(seismic$gdenergy, col = 2)
qqnorm(seismic$maxenergy);qqline(seismic$maxenergy, col = 2)
qqnorm(seismic$nbumps);qqline(seismic$nbumps, col = 2)
qqnorm(seismic$nbumps2);qqline(seismic$nbumps2, col = 2)
qqnorm(seismic$nbumps3);qqline(seismic$nbumps3, col = 2)
qqnorm(seismic$nbumps4);qqline(seismic$nbumps4, col = 2)
qqnorm(seismic$nbumps5);qqline(seismic$nbumps5, col = 2)
qqnorm(seismic$nbumps6);qqline(seismic$nbumps6, col = 2)
qqnorm(seismic$nbumps7);qqline(seismic$nbumps7, col = 2)
qqnorm(seismic$nbumps89);qqline(seismic$nbumps89, col = 2)
qqnorm(seismic$energy);qqline(seismic$energy, col = 2)


```

# Correlation of the Variables 

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
# Correlation Plot of the data...7 variables removed
source("http://www.sthda.com/upload/rquery_cormat.r")
x <- seismic[c(-1,-2,-3,-8,-14,-15,-16,-19)]
require("corrplot")
rquery.cormat(x, type="flatten", graphType = "heatmap")
rquery.cormat(x, type="flatten")

#rquery.cormat(x, type="flatten", graph=FALSE)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
### Making nice and pretty
### Nothing is normalized or standardized...unsure if we need to do that

### Dropping seismic for now...maybe should be our focus
seismic <- seismic[,-2]

### Renaming response variable
seismic <- rename(seismic, c(seismic="y.train"))

#2584x19 matrix
n=dim(seismic)[1]
p=dim(seismic)[2]

# Setting up 
set.seed(2016)
test=sample(n, round(n/4))

### Seperating data into Test and Training Sets
# Train
y.train <- seismic$y[-test]
X.train <- seismic[-test,]

# Test
y.test <- seismic$y[test]
X.test <- seismic[test,]

### Training Data Matrix
### 1938 obs in Training Set
seismic.train <- as.data.frame(cbind(y.train,X.train))
seismic.train <- seismic.train[,-2]

### Testing Data Matrix
### 646 obs in Test Set
seismic.test <- as.data.frame(cbind(y.test, X.test))
seismic.test <- seismic.test[,-2]

#View(seismic.train)
#View(seismic.test)
```

# Linear regression of an indicator matrix

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
# Setting Graphics parameters
par(mfrow=c(1,1))

## Getting data ready to perform pca/indactor matrix
setwd("/Users/benStraub/Desktop/557/Project 2")
RawData <- read.csv("seismic.csv",sep=",", dec=",")
RawData$seismic <- as.integer(RawData$seismic  == "a")
RawData <- RawData[c(-2,-3,-8,-14,-15,-16,-19)]#getting rid of factor variable for now, nbumps greater than five have almost entirely 0 columns
#RawData <- RawData[-1,]#getting rid of variables names to run pca
responseY <- RawData[1]#selecting our response of interest
predictorX <- RawData[,2:11]

#running pca
pc.comp <- princomp(scale(predictorX)) 

#Creates screeplot to figure out which pc's to include
screeplot(pc.comp, type="lines")
pc.comp <- princomp(scale(predictorX))$scores 
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
par(mfrow=c(1,1))

#Based on scree plot im going to go with 3 pc scores
pc.comp1 <- pc.comp[,1] 
pc.comp2 <- pc.comp[,2] 
pc.comp3 <- pc.comp[,3] 
X <- cbind(1,pc.comp1, pc.comp2,pc.comp3)

#View(RawData)
#View(predictorX)
#View(responseY)

# Following LeBao's code
class1 <- which(responseY==1) 
class2 <- which(responseY==0) 
Y <- matrix(0,dim(responseY)[1],2) 
Y[class2,1] <- 1 
Y[class1,2] <- 1

betaHat <- solve(t(X)%*%X)%*%t(X)%*%Y 
Y1 <- X%*%betaHat[,1] 
Y2 <- X%*%betaHat[,2]

# Plots the pca scores...doesn't look good.
plot(pc.comp1[class1],pc.comp2[class1],main="PC1 vs PC2",xlab="pcaComp1",ylab="pcaComp2",col="red") 
points(pc.comp1[class2],pc.comp2[class2],col="blue")

plot(pc.comp1[class1],pc.comp3[class1],main="PC1 vs PC3",xlab="pcaComp1",ylab="pcaComp2",col="red") 
points(pc.comp1[class2],pc.comp3[class2],col="blue")

plot(pc.comp2[class1],pc.comp3[class1],main="PC2 vs PC3",xlab="pcaComp1",ylab="pcaComp2",col="red") 
points(pc.comp2[class2],pc.comp3[class2],col="blue")

```


# Logistic Regression on the Training and Test Sets

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

############# LOGISTIC REGRESSION ###################

### Training Set on Logistic Regression
glm.fit=glm(y.train~., data=seismic.train ,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit ,type="response")

```

The predictors that are significant in our logistic model are genergy, gpuls and ghazardb and a couple more.  The predictors nbumps6, nbumps7 and nbumps89 are not defined due to singularities, which may indicated collinearity.

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
### Training Set on Logistic Regression Continued
#glm.probs[1:10]
#contrasts(seismic.train$y.train)

glm.pred=rep("a",1938)
glm.pred[glm.probs >.5]="b"
table(glm.pred ,y.train)
mean(glm.pred==y.train)

```

The diagonal elements of the confusion matrix indicate correct predictions,
while the off-diagonals represent incorrect predictions. Hence our model on the training data set correctly predicted that the seismic activity would be of no harzard on 1176 observations and that it would be a low hazard on 230 observations, for a total of 1176 + 230 = 1406 correct predictions. The mean() function can be used to compute the fraction of seismic activity for which the prediction was correct. In this case, logistic regression correctly predicted the movement of the market 73 percent of the time.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
### Testing Set on Logistic Regression
glm.fit=glm(y.test~., data=seismic.test ,family=binomial)
glm.probs=predict(glm.fit, type="response")

glm.pred=rep("a",646)
glm.pred[glm.probs >.5]="b"
table(glm.pred, y.test)
mean(glm.pred==y.test)
```

The diagonal elements of the confusion matrix indicate correct predictions,
while the off-diagonals represent incorrect predictions. Hence our model on the testing data set correctly predicted that the seismic activity would be of no harzard on 352 observations and that it would be a low hazard on 110 days, for a total of 352 + 110 = 462 correct predictions. The mean() function can be used to compute the fraction of seismic activity for which the prediction was correct. In this case, logistic regression correctly predicted the movement of the market 71.5 percent of the time.

Recall that the logistic regression model had only 7ish predictors that were significant from an avaiable 17.  Perhaps by removing the variables that appear not to be helpful in predicting seismic hazard, we can obtain a more effective model. After all, using predictors that have no relationship with the response tends to cause a deterioration in the test error rate (since such predictors cause an increase in variance without a corresponding decrease in bias), and so removing such predictors may in turn yield an improvement [straight from the book]