---
title: "557_Project_2BS"
author: "Ben Straub, Hillary Koch, Jiawei Huang, Arif Masrur"
date: "3/15/2017"
output: pdf_document
---

# No Command Lines Ever.  Whoa

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Configuring Space
rm(list=ls())

# Loading packages into R
library(data.table);library(car);library(lars);library(knitr);library(ISLR);library(leaps);library(glmnet);library(MASS);library(reshape);library(ggplot2);library(pROC)
library(klaR)

# Loading up files
setwd("/Users/benStraub/Desktop/557/Project 2")
seismic <- read.csv("seismic.csv")
```

## What the Factor Variables look like

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
par(mfrow=c(2,2))

# Barplots of Factor Variables
counts <- table(seismic$class)
barplot(counts, main="Class/Response Distribution", 
  	xlab="Number of Obs")
counts <- table(seismic$seismic)
barplot(counts, main="Seismic Distribution", 
  	xlab="Number of Obs")
counts <- table(seismic$seismoacoustic)
barplot(counts, main="Seismoacoustic Distribution", 
  	xlab="Number of Obs")
counts <- table(seismic$ghazard)
barplot(counts, main="Ghazard Distribution", 
  	xlab="Number of Obs")
```

## What the Continuous Variables look like

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, cache=TRUE}
par(mfrow=c(2,2))

## Looking at condtl distb within class
## Have a look at the densities

plot(density(seismic$genergy));plot(density(seismic$gpuls))

#plot(density(log(seismic$genergy)));plot(density(log(seismic$gpuls)))

plot(density(seismic$gdenergy));plot(density(seismic$gdpuls))
plot(density(seismic$maxenergy));plot(density(seismic$nbumps, adjust=10))
plot(density(seismic$nbumps2,adjust=10));plot(density(seismic$nbumps3,adjust=10))
plot(density(seismic$nbumps4,adjust=10));plot(density(seismic$nbumps5,adjust=10))

##---------------------------------------------
## Some quick EDA from Hillary
##---------------------------------------------

## Normalize things that arent factors
## Eliminate data that has no info (some of the nbumps)

seismic[,c(4:7,9:13,17:18)] <- seismic[,c(4:7,9:13,17:18)]
seismic <- seismic[,-(14:16)]
#seismic$class <- as.factor(seismic$class)

for(i in c(1:3,8)){
  seismic[,i] <- as.numeric(seismic[,i])
}

fit <- lm(class~., data = seismic)
summary(fit)

#pairs(seismic)

## qqplots, except for factors
for(i in c(4:7,9:15)){
  eval(parse(text = paste0("qqnorm(seismic$",names(seismic)[i],")")))
  eval(parse(text = paste0("qqline(seismic$",names(seismic)[i],", col = 2)")))
}

## Check out the residuals
res <- fit$residuals
fitvals <- fit$fitted
plot(fitvals, res, xlab = "Fitted Values", ylab = "Residuals")
abline(h=0, col = 'red')
hist(res, xlab = "Residuals")
```

## Lots of multicollinearity to worry about during variable selection

```{r}
vif(fit)
```

# Correlation of the Variables 

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, cache=TRUE}
# Correlation Plot of the data...7 variables removed
source("http://www.sthda.com/upload/rquery_cormat.r")
x <- seismic[c(-1,-2,-3,-8,-14,-15,-16,-19)]
require("corrplot")
rquery.cormat(x, graphType = "heatmap")
#rquery.cormat(x, type="flatten")

# Not sure how to suppress the the output.  Just want the plot.
```

# Separating into Test and Training Sets

```{r, echo=TRUE, warning=FALSE, message=FALSE, comment=NA}
##------------------------------------
## Setting up Test and Training Sets
##------------------------------------

n <- dim(seismic)[1]
p <- dim(seismic)[2]

set.seed(2016)
test <- sample(n, round(n/4))
train <- (1:n)[-test]
seismic.train <- seismic[train,]
seismic.test <- seismic[test,]

dim(seismic)
dim(seismic.train)
dim(seismic.test)

#View(seismic.train)
#View(seismic.test)
```

# Linear regression of an indicator matrix

```{r}
##----------------------------------------
## Linear regression of indicator matrix
##----------------------------------------

responseY <- seismic$class
predictorX <- seismic[,-16]

# Following Le Bao's code
class1 <- which(responseY==1) 
class0 <- which(responseY==0) 
Y <- matrix(data = rep(0,length(responseY)*2),nrow = length(responseY)) 
Y[class0,1] <- 1 
Y[class1,2] <- 1

betaHat <- solve(t(as.matrix(predictorX))%*%as.matrix(predictorX))%*%t(as.matrix(predictorX))%*%Y
Y1 <- as.matrix(predictorX)%*%betaHat[,1]
Y2 <- as.matrix(predictorX)%*%betaHat[,2]

pred.mx <- cbind(Y1,Y2)
pred <- rep(NA,length(Y1))
for(i in 1:length(Y1)){
  pred[i] <- which.max(pred.mx[i,]) - 1
}

# Confusion matrix
mx <- cbind(pred,responseY,pred-responseY)

confusion <- matrix(rep(NA,4), nrow = 2)
correct <- which(mx[,3] == 0)
confusion[1,1] <- length(which(mx[correct,1] == 0))
confusion[2,2] <- length(which(mx[correct,1] == 1))
confusion[1,2] <- length(which(mx[,3] == -1))
confusion[2,1] <- length(which(mx[,3] == 1))
confusion

sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])
error.rate <- (confusion[1,2] + confusion[2,1])/sum(confusion)
c(sensitivity, specificity, error.rate)

```

# Linear Discriminant Analysis on full model

```{r, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
##------------------------------------
## Fit LDA model
##------------------------------------

lda.fit <- lda(class~., data = seismic, subset = train)

##
## Predict back onto training data
##

lda.pred <- predict(lda.fit, seismic.train)
lda.class.train <- lda.pred$class

## Confusion matrix
confusion <- table(lda.class.train,seismic.train$class)
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

## Sensitivity is very bad! Dramatically underpredict 1s
confusion
sensitivity
specificity

##
## Here is a function that could calculate overall error rates
## as a function of the posterior prediction probability threshhold
##

mod.posterior <- function(posterior, truth, prob, dimension = length(train)){
  idx0 <- which(posterior[,1] > prob)
  idx1 <- (1:dimension)[-idx0]
  
  prediction <- rep(NA,dimension)
  prediction[idx0] = 0
  prediction[idx1] = 1
  
  mx <- cbind(prediction,truth,prediction-truth)
  
  confusion <- matrix(rep(NA,4), nrow = 2)
  correct <- which(mx[,3] == 0)
  confusion[1,1] <- length(which(mx[correct,1] == 0))
  confusion[2,2] <- length(which(mx[correct,1] == 1))
  confusion[1,2] <- length(which(mx[,3] == -1))
  confusion[2,1] <- length(which(mx[,3] == 1))
  
  sensitivity <- confusion[2,2]/sum(confusion[,2])
  specificity <- confusion[1,1]/sum(confusion[,1])
  error.rate <- (confusion[1,2] + confusion[2,1])/sum(confusion)
  c(sensitivity, specificity, error.rate)
}

posterior.train <- lda.pred$posterior
truth.train <- seismic.train$class

prob.seq <- seq(.5,.98,by = .02)
output.train <- matrix(rep(NA,length(prob.seq)*2), ncol = 2)
colnames(output.train) <- c("Sensitivity", "Error.rate")

for(i in 1:length(prob.seq)){
  output.train[i,] <- mod.posterior(posterior.train,truth.train,prob.seq[i])[c(1,3)]
}

df1 <- as.data.frame(cbind(prob.seq,output.train))

ggplot(data = df1, aes(x=prob.seq)) +
  geom_line(aes(y = Sensitivity, colour = "Sensitivity"), linetype = "dashed") +
  geom_line(aes(y = Error.rate, colour = "Error rate")) +
  scale_colour_manual(values=c("dark cyan", "dark grey"))
  


##
## Now try on test data
##

lda.pred.test <- predict(lda.fit, seismic.test)
lda.class.test <- lda.pred$class

posterior.test <- lda.pred$posterior
truth.test <- seismic.test$class

## Confusion matrix
confusion <- table(lda.class.test,seismic.test$class)
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

# Sensitivity is slightly worse here
confusion
sensitivity
specificity

output.test <- matrix(rep(NA,length(prob.seq)*2), ncol = 2)
colnames(output.test) <- c("Sensitivity", "Error.rate")

for(i in 1:length(prob.seq)){
  output.test[i,] <- mod.posterior(posterior.test,truth.test,prob.seq[i])[c(1,3)]
}

df2 <- as.data.frame(cbind(prob.seq,output.test))

ggplot(data = df2, aes(x=prob.seq)) +
  geom_line(aes(y = Sensitivity, colour = "Sensitivity"), linetype = "dashed") +
  geom_line(aes(y = Error.rate, colour = "Error rate")) +
  scale_colour_manual(values=c("dark cyan", "dark grey"))

##
## ROC curves
##

prob.seq <- seq(0,1,length = 500)
ROC.train <- matrix(rep(NA,length(prob.seq)*2), ncol = 2)
colnames(ROC.train) <- c("Sensitivity", "1-Specificity")
for(i in 1:length(prob.seq)){
  ROC.train[i,] <- mod.posterior(posterior.train,truth.train,prob.seq[i])[c(1,2)]
}

ROC.train[,2] <- 1-ROC.train[,2]

ROC.test <- matrix(rep(NA,length(prob.seq)*2), ncol = 2)
colnames(ROC.test) <- c("Sensitivity", "1-Specificity")
for(i in 1:length(prob.seq)){
  ROC.test[i,] <- mod.posterior(posterior.test,truth.test,prob.seq[i])[c(1,2)]
}

ROC.test[,2] <- 1-ROC.test[,2]

plot(x=ROC.test[,2],y=ROC.test[,1], pch = '.', ylim = c(0,1), xlim = c(0,1), col = "dark cyan", xlab = "False positive rate", ylab = "True positive rate")
lines(x=ROC.test[,2],y=ROC.test[,1], ylim = c(0,1), xlim = c(0,1), col = "dark cyan")
lines(x = ROC.train[,2],y=ROC.train[,1], ylim = c(0,1), xlim = c(0,1))
lines(x=prob.seq,y=prob.seq)

```

# Quadratic Discriminant Analysis -INCOMPLETE

```{r}
##------------------------------------
## Fit QDA model
##------------------------------------

## Currently, can't perform QDA.  This is probably due to multicollinearity in the model
## (can't invert covariance matrix) but should be possible after variable selection

#qda.fit <- qda(class~., data = seismic, subset = train)
```

# Regularized Discriminant Analysis -INCOMPLETE

```{r}
##------------------------------------
## Fit RDA model
##------------------------------------

## Currently, can't perform RDA.  This is probably due to multicollinearity in the model
## (can't invert covariance matrix) but should be possible after variable selection
```

# Logistic Regression

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

##--------------------------------------------
## Logistic Regression  Confusion\Roc
##--------------------------------------------

# Model fitted to Training Data
glm.train <- glm(class~., seismic.train, family=binomial)

# Model Summary
summary(glm.train)

glm.probs=predict(glm.train, type="response")

glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"
confusion <- table(glm.pred ,seismic.train$class)
mean(glm.pred==seismic.train$class)

roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")

# Confusion Table
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

# Using Training model on Test Data
glm.probs=predict(glm.train, seismic.test, type="response")

glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"
confusion <- table(glm.pred, seismic.test$class)
mean(glm.pred==seismic.test$class)

# Confusion Table
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

roc.Test <- roc(seismic.test$class, glm.probs, direction="<")

# Plotting Roc Curve for Test Data
plot.roc(roc.Test, col="blue", auc.polygon=TRUE,main="ROC Curve", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Train, add=TRUE)
```

# Variable Selection-LASSO

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
##-----------------------------------------------------
## LASSO 
##-----------------------------------------------------

# Setting up Train and Test
grid=10^seq(10,-2,length=100)
X.train=seismic.train[-16]
X.train=as.matrix(X.train)
y.train=seismic.train$class
X.test = seismic.test[-16]
X.test = as.matrix(X.test)
y.test = seismic.test$class

# Running on Train set
lasso.mod=glmnet(X.train,y.train,alpha=1,lambda=grid, family = "binomial")


plot(lasso.mod,xvar="lambda",label=TRUE) 

# Using CV to find lambda
set.seed(1)
cv.out=cv.glmnet(X.train,y.train,alpha=1)
plot(cv.out,xvar="lambda",label=TRUE) 

# Running on Test set using CV lambda
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=X.test)
mean((lasso.pred-y.test)^2)
out=glmnet(X.train,y.train,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:16,]
lasso.coef

```

# Variables selected through LASSO

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

lasso.coef[lasso.coef!=0]

```

# Principal Component Analysis from the Book - INCOMPLETE

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

par(mfrow=c(2,2))

pr.out=prcomp(seismic, scale=TRUE)

vars <- names(seismic)

Cols=function(vec){
    cols=rainbow(length(unique(vec)))
    return(cols[as.numeric(as.factor(vec))])
}

par(mfrow=c(2,2))
plot(pr.out$x[,1:2], col=Cols(vars), pch=19,xlab="Z1",ylab="Z2")
plot(pr.out$x[,c(1,3)], col=Cols(vars), pch=19,xlab="Z1",ylab="Z3")
summary(pr.out)
plot(pr.out)
pve=100*pr.out$sdev^2/sum(pr.out$sdev^2)
par(mfrow=c(1,2))
plot(pve,  type="o", ylab="PVE", xlab="Principal Component", col="blue")
plot(cumsum(pve), type="o", ylab="Cumulative PVE", xlab="Principal Component", col="brown3")

library(pls)
set.seed(2)
pcr.fit=pcr(class~., data=seismic,scale=TRUE,validation="CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type="MSEP")
set.seed(1)
pcr.fit=pcr(class~., data=seismic,subset=train,scale=TRUE, validation="CV")
validationplot(pcr.fit,val.type="MSEP")
pcr.pred=predict(pcr.fit,seismic.test,ncomp=7)
mean((pcr.pred-seismic.test$class)^2)
#pcr.fit=pcr(class~.,scale=TRUE,ncomp=7)

summary(pcr.fit)


```

# Variable Selection - PCA - INCOMPLETE

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
##-----------------------------------------------------
## Principle Component Analysis 
##-----------------------------------------------------

# Setting Graphics parameters
par(mfrow=c(1,1))

## Getting data ready to perform pca/indactor matrix
RawData.train <- seismic.train

responseY <- RawData.train[16]#selecting our response of interest
predictorX <- RawData.train[,1:15]

#running pca
pc.comp <- princomp(scale(predictorX)) 

#Creates screeplot to figure out which pc's to include
screeplot(pc.comp, type="lines")
pc.comp <- princomp(scale(predictorX))$scores 

## Look at test data performance
```

# Variable Selection - PCA - INCOMPLETE

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
##-----------------------------------------------------
##  Principle Component Analysis 
##-----------------------------------------------------

par(mfrow=c(1,1))

#Based on scree plot im going to go with 3 pc scores
pc.comp1 <- pc.comp[,1] 
pc.comp2 <- pc.comp[,2] 
pc.comp3 <- pc.comp[,3] 
X <- cbind(1,pc.comp1, pc.comp2,pc.comp3)


# Following LeBao's code
class1 <- which(responseY==1) 
class2 <- which(responseY==0) 
Y <- matrix(0,dim(responseY)[1],2) 
Y[class2,1] <- 1 
Y[class1,2] <- 1

betaHat <- solve(t(X)%*%X)%*%t(X)%*%Y 
Y1 <- X%*%betaHat[,1] 
Y2 <- X%*%betaHat[,2]

# Plots the pca scores...doesn't look good.
plot(pc.comp1[class1],pc.comp2[class1],main="PC1 vs PC2",xlab="pcaComp1",ylab="pcaComp2",col="red") 
points(pc.comp1[class2],pc.comp2[class2],col="blue")

plot(pc.comp1[class1],pc.comp3[class1],main="PC1 vs PC3",xlab="pcaComp1",ylab="pcaComp2",col="red") 
points(pc.comp1[class2],pc.comp3[class2],col="blue")

plot(pc.comp2[class1],pc.comp3[class1],main="PC2 vs PC3",xlab="pcaComp1",ylab="pcaComp2",col="red") 
points(pc.comp2[class2],pc.comp3[class2],col="blue")

library(pls)
set.seed(2)
pcr.fit=pcr(class~., data=seismic,scale=TRUE,validation="CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type="MSEP")
set.seed(1)
pcr.fit=pcr(class~., data=seismic,subset=train,scale=TRUE, validation="CV")
validationplot(pcr.fit,val.type="MSEP")
pcr.pred=predict(pcr.fit,seismic.test,ncomp=7)
mean((pcr.pred-seismic.test$class)^2)
#pcr.fit=pcr(y~x,scale=TRUE,ncomp=7)
#summary(pcr.fit)

## Not sure how to figure out misclasssfication rate for Training Date Sets
## Not sure how to run the Testing Data through the model
```

# Logistic Regression after Variable Selection

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

##--------------------------------------------
## Logistic Regression  after Variable Selection
##--------------------------------------------

# Model fitted to Training Data
glm.train <- glm(class~seismic+shift+gpuls+nbumps, seismic.train, family=binomial)

# Model Summary
summary(glm.train)

glm.probs=predict(glm.train, type="response")

glm.pred=rep("0",1938)
glm.pred[glm.probs >.5]="1"
confusion <- table(glm.pred ,seismic.train$class)
mean(glm.pred==seismic.train$class)

roc.Train <- roc(seismic.train$class, glm.probs, direction = "<")

# Confusion Table
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

# Using Training model on Test Data
glm.probs=predict(glm.train, seismic.test, type="response")

glm.pred=rep("0",646)
glm.pred[glm.probs >.5]="1"
confusion <- table(glm.pred, seismic.test$class)
mean(glm.pred==seismic.test$class)

# Confusion Table
sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

roc.Test <- roc(seismic.test$class, glm.probs, direction="<")

# Plotting Roc Curve for Test Data
plot.roc(roc.Test, col="blue", auc.polygon=TRUE,main="ROC Curve after Variable Selection", xlab="False Positive Rate", ylab="True Positive Rate", print.auc=TRUE)
plot.roc(roc.Train, add=TRUE)
```

# Quadratic Discriminant Analysis after variable selection

```{r}
##-----------------------------------------
## Fit QDA model after variable selection
##-----------------------------------------

# Model 1
qda.fit <- qda(class~seismic+shift+gpuls+nbumps, data=seismic.train)
qda.class=predict(qda.fit,seismic.test)$class
confusion <- table(qda.class ,seismic.test$class)

sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

# Model 2
qda.fit <- qda(class ~ genergy + gpuls + nbumps + nbumps2 + nbumps4, data=seismic.train)
qda.class=predict(qda.fit,seismic.test)$class

confusion <- table(qda.class ,seismic.test$class)

sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

```


# Regularized Discriminant Analysis after variable selection

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}

##------------------------------------------------------------
## Regularized Discriminant Analysis after variable selection
##------------------------------------------------------------

# Model 1

rda.fit <- rda(class~seismic+shift+gpuls+nbumps, data = seismic.train, gamma = 0.05, lambda = 0.2)

rda.class=predict(rda.fit,seismic.test)$class

confusion <- table(rda.class ,seismic.test$class)

sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

# Model 2

rda.fit <- rda(class~genergy + gpuls + nbumps + nbumps2 + nbumps4, data = seismic.train, gamma = 1, lambda = 1)

rda.class=predict(rda.fit,seismic.test)$class

confusion <- table(rda.class ,seismic.test$class)

sensitivity <- confusion[2,2]/sum(confusion[,2])
specificity <- confusion[1,1]/sum(confusion[,1])

confusion
sensitivity
specificity

```

